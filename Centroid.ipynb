{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d06a97-c380-4816-a1bb-5cd1c41733fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install opencv-python\n",
    "!pip install numpy\n",
    "!pip install Pillow\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c42a79d-c237-4278-9bdc-7492e76e8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import scipy\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313e131c-60cd-4f27-87f6-05d50d568a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\batikan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-1-24 Python-3.11.5 torch-2.1.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 182 layers, 7246518 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "prev_time = 0\n",
    "\n",
    "#yolov5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weight.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(\"x.mp4\")\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "dt = 1/30.0\n",
    "kf = cv2.KalmanFilter(6, 2)\n",
    "kf.measurementMatrix = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]], np.float32)  \n",
    "kf.transitionMatrix = np.array([[1, 0, 0, dt, 0, 0], [0, 1, 0, 0, dt, 0], [0, 0, 1, 0, 0, dt],\n",
    "                                [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]], np.float32)  \n",
    "kf.processNoiseCov = 1e-5 * np.eye(6, dtype=np.float32)  \n",
    "kf.measurementNoiseCov = 1e-3 * np.eye(2, dtype=np.float32) \n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "record = cv2.VideoWriter('record.mp4', fourcc, 5, (960,5))\n",
    "\n",
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=50):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = {}\n",
    "        self.disappeared = {}\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        if len(rects) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            return self.objects\n",
    "\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        else:\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            D = scipy.spatial.distance.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                for row in unusedRows:\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "\n",
    "        return self.objects\n",
    "\n",
    "centroid_tracker = CentroidTracker()\n",
    "\n",
    "# Variables for the timer\n",
    "timer_start = None\n",
    "inside_time = 0\n",
    "lock_duration = 5  # Locking time (seconds)\n",
    "is_inside = False\n",
    "\n",
    "while True:\n",
    "    new_frame = time.time()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = model(Image.fromarray(img))\n",
    "\n",
    "    rects = []\n",
    "    for obj_temp in results.xyxy[0]:\n",
    "        x1, y1, x2, y2, conf, cls = obj_temp.tolist()\n",
    "        if conf > 0.5:\n",
    "            obj = np.array([[(x1 + x2) / 2], [(y1 + y2) / 2], [0], [0], [0], [0]], dtype=np.float32)\n",
    "            prediction = kf.predict()\n",
    "            kf.correct(obj[:2])\n",
    "            x, y, z, dx, dy, dz = prediction.ravel()\n",
    "            x, y = int(x), int(y)\n",
    "            rects.append((x - 10, y - 10, x + 10, y + 10))\n",
    "\n",
    "    if rects:  # continue if rects are not empty\n",
    "        objects = centroid_tracker.update(rects)\n",
    "\n",
    "        for (objectID, centroid) in objects.items():\n",
    "            x, y = centroid\n",
    "            cv2.rectangle(frame, (x - 10, y - 10), (x + 10, y + 10), (0, 255, 0), 2)\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Check if it is within the specified rectangle\n",
    "        if int(img.shape[1] / 4) < x < int(3 * img.shape[1] / 4) and int(img.shape[0] / 10) < y < int(9 * img.shape[0] / 10):\n",
    "            if not is_inside:\n",
    "                timer_start = time.time()\n",
    "                is_inside = True\n",
    "        else:\n",
    "            if is_inside:\n",
    "                is_inside = False\n",
    "                timer_start = None\n",
    "                inside_time = 0\n",
    "\n",
    "        # Timer operations\n",
    "        if timer_start:\n",
    "            elapsed_time = time.time() - timer_start\n",
    "            inside_time = elapsed_time\n",
    "\n",
    "            if elapsed_time > lock_duration:\n",
    "                cv2.putText(frame, f\"Lock Successful! ({elapsed_time:.2f} seconds)\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, f\"Locking... ({elapsed_time:.2f} seconds)\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Draw the line\n",
    "        for i in range(1, len(objects)):\n",
    "            if list(objects.values())[i - 1] is not None and list(objects.values())[i] is not None:\n",
    "                pts = np.array([list(objects.values())[i - 1], list(objects.values())[i]], np.int32)\n",
    "                pts = pts.reshape((-1, 1, 2))\n",
    "                cv2.polylines(frame, [pts], False, (0, 255, 0), 2)\n",
    "\n",
    "    x1 = int(0.25 * cap.get(3))  \n",
    "    y1 = int(0.1 * cap.get(4))  \n",
    "    x2 = int(0.75 * cap.get(3))  \n",
    "    y2 = int(0.9 * cap.get(4))  \n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    for obj_temp in results.xyxy[0]:\n",
    "        x1, y1, x2, y2, conf, cls = obj_temp.tolist()\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        if conf > 0.5:\n",
    "            label = f'{model.names[int(cls)]} {conf:.2f}'\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time)\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(frame, f'FPS: {fps:.2f}', (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow(\"detect\", frame)\n",
    "\n",
    "    record.write(frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "record.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d91c914-2a66-4132-aa73-75222290ebc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ad498-4228-4036-a40d-35edd9472a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
